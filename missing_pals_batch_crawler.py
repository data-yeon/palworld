#!/usr/bin/env python3
"""
íŒ°ì›”ë“œ ëˆ„ë½ íŒ° ë°°ì¹˜ í¬ë¡¤ë§ ìŠ¤í¬ë¦½íŠ¸
MCP Firecrawlì„ í™œìš©í•˜ì—¬ 92ê°œ ëˆ„ë½ íŒ° ë°ì´í„° ìˆ˜ì§‘
"""

import json
import time
import csv
import os
from datetime import datetime
from typing import Dict, List, Any, Optional
import requests

class PalBatchCrawler:
    def __init__(self):
        self.base_url = "https://palworld.fandom.com/wiki/"
        self.crawled_data = {}
        self.failed_pals = []
        self.session_start = datetime.now()
        
        # ëˆ„ë½ëœ íŒ° ëª©ë¡ ì •ì˜
        self.missing_pals = self.get_missing_pal_list()
        
    def get_missing_pal_list(self) -> Dict[str, List[str]]:
        """ëˆ„ë½ëœ íŒ° ëª©ë¡ì„ ì¹´í…Œê³ ë¦¬ë³„ë¡œ ë°˜í™˜"""
        return {
            "basic_pals": [str(i) for i in range(116, 156)],  # 116-155
            "b_variants": [
                "23B", "24B", "25B", "31B", "32B", "33B", "35B", "37B", "39B", "40B",
                "43B", "45B", "58B", "61B", "62B", "64B", "65B", "72B", "75B", "76B",
                "80B", "81B", "82B", "83B", "85B", "86B", "88B", "89B", "90B", "92B",
                "95B", "99B", "101B", "102B", "105B", "112B", "116B", "148B", "152B", "153B", "154B"
            ],
            "s_series": [f"S{i}" for i in range(1, 12)]  # S1-S11
        }
    
    def get_pal_wiki_url(self, pal_id: str) -> str:
        """íŒ° IDë¥¼ ê¸°ë°˜ìœ¼ë¡œ ìœ„í‚¤ URL ìƒì„±"""
        # ê¸°ë³¸ íŒ° (ìˆ«ìë§Œ)
        if pal_id.isdigit():
            # ê¸°ì¡´ ë°ì´í„°ì—ì„œ ì˜ì–´ ì´ë¦„ ë§¤í•‘ í•„ìš”
            pal_name_mapping = {
                "116": "Shroomer",
                "117": "Kikit", 
                "118": "Sootseer",
                "119": "Prixter",
                "120": "Knocklem",
                "121": "Yakumo",
                "122": "Dogen",
                "123": "Dazemu",
                "124": "Mimog",
                "125": "Xenovader",
                "126": "Xenogard",
                "127": "Xenolord",
                "128": "Nitemary",
                "129": "Starryon",
                "130": "Silvegis",
                "131": "Smokie",
                "132": "Celesdir",
                "133": "Omascul",
                "134": "Splatterina",
                "135": "Tarantriss",
                "136": "Azurmane",
                "137": "Bastigor",
                "138": "Prunelia",
                "139": "Nyafia",
                "140": "Gildane",
                "141": "Herbil",
                "142": "Icelyn",
                "143": "Frostplume",
                "144": "Palumba",
                "145": "Braloha",
                "146": "Munchill",
                "147": "Polapup",
                "148": "Turtacle",
                "149": "Jellroy",
                "150": "Jelliette",
                "151": "Gloopie",
                "152": "Finsider",
                "153": "Ghangler",
                "154": "Whalaska",
                "155": "Neptilius"
            }
            return f"{self.base_url}{pal_name_mapping.get(pal_id, f'Pal_{pal_id}')}"
        
        # B ì•„ì¢… íŒ°ë“¤
        elif 'B' in pal_id:
            base_num = pal_id.replace('B', '')
            # B ì•„ì¢… ë§¤í•‘ ë¡œì§ (ê¸°ì¡´ ë°ì´í„° ì°¸ì¡° í•„ìš”)
            return f"{self.base_url}Pal_{pal_id}"
            
        # S ì‹œë¦¬ì¦ˆ
        elif pal_id.startswith('S'):
            s_mapping = {
                "S1": "Green_Slime",
                "S2": "Blue_Slime", 
                "S3": "Red_Slime",
                "S4": "Purple_Slime",
                "S5": "Illuminant_Slime",
                "S6": "Rainbow_Slime",
                "S7": "Enchanted_Sword",
                "S8": "Cave_Bat",
                "S9": "Illuminant_Bat",
                "S10": "Eye_of_Cthulhu",
                "S11": "Demon_Eye"
            }
            return f"{self.base_url}{s_mapping.get(pal_id, f'Special_{pal_id}')}"
        
        return f"{self.base_url}Pal_{pal_id}"
    
    def crawl_single_pal(self, pal_id: str) -> Optional[Dict[str, Any]]:
        """MCP Firecrawlì„ ì‚¬ìš©í•˜ì—¬ ë‹¨ì¼ íŒ° ë°ì´í„° í¬ë¡¤ë§"""
        url = self.get_pal_wiki_url(pal_id)
        
        try:
            print(f"ğŸ” í¬ë¡¤ë§ ì¤‘: {pal_id} ({url})")
            
            # MCP Firecrawl í˜¸ì¶œ (ì‹¤ì œ êµ¬í˜„ ì‹œ MCP ë„êµ¬ ì‚¬ìš©)
            # ì—¬ê¸°ì„œëŠ” êµ¬ì¡°ë¥¼ ë³´ì—¬ì£¼ëŠ” ì˜ˆì‹œ
            pal_data = self.extract_pal_data_from_url(url, pal_id)
            
            if pal_data:
                print(f"âœ… ì„±ê³µ: {pal_id} - {pal_data.get('name', 'Unknown')}")
                return pal_data
            else:
                print(f"âŒ ì‹¤íŒ¨: {pal_id} - ë°ì´í„° ì¶”ì¶œ ì‹¤íŒ¨")
                self.failed_pals.append(pal_id)
                return None
                
        except Exception as e:
            print(f"âŒ ì˜¤ë¥˜: {pal_id} - {str(e)}")
            self.failed_pals.append(pal_id)
            return None
    
    def extract_pal_data_from_url(self, url: str, pal_id: str) -> Optional[Dict[str, Any]]:
        """URLì—ì„œ íŒ° ë°ì´í„° ì¶”ì¶œ (MCP Firecrawl ë˜í¼)"""
        # ì‹¤ì œ MCP Firecrawl í˜¸ì¶œ ë¡œì§
        # ì—¬ê¸°ì„œëŠ” êµ¬ì¡°ë§Œ ë³´ì—¬ì¤Œ
        
        # ê¸°ë³¸ ë°ì´í„° êµ¬ì¡°
        pal_data = {
            "id": pal_id,
            "name": "",
            "englishName": "",
            "description": "",
            "type1": "",
            "type2": "",
            "hp": "",
            "attack": "",
            "defense": "",
            "rarity": "",
            "size": "",
            "foodAmount": "",
            "partnerSkill": "",
            "work1": "",
            "work2": "",
            "work3": "",
            "activeSkills": "",
            "dropItem1": "",
            "dropItem2": "",
            "eggType": "",
            "imageFile": f"{pal_id}_menu.webp"
        }
        
        # TODO: ì‹¤ì œ MCP Firecrawl êµ¬í˜„
        # extracted_data = mcp_firecrawl.scrape(url, extract_schema=pal_schema)
        
        return pal_data
    
    def batch_crawl_category(self, category: str, pal_list: List[str], batch_size: int = 5):
        """ì¹´í…Œê³ ë¦¬ë³„ ë°°ì¹˜ í¬ë¡¤ë§"""
        print(f"\nğŸš€ {category} ì¹´í…Œê³ ë¦¬ í¬ë¡¤ë§ ì‹œì‘ ({len(pal_list)}ê°œ)")
        
        for i in range(0, len(pal_list), batch_size):
            batch = pal_list[i:i + batch_size]
            print(f"\nğŸ“¦ ë°°ì¹˜ {i//batch_size + 1}: {batch}")
            
            for pal_id in batch:
                pal_data = self.crawl_single_pal(pal_id)
                if pal_data:
                    self.crawled_data[pal_id] = pal_data
                
                # ìš”ì²­ ê°„ ë”œë ˆì´ (ìœ„í‚¤ ì„œë²„ ë³´í˜¸)
                time.sleep(1)
            
            # ë°°ì¹˜ ê°„ ë” ê¸´ ë”œë ˆì´
            time.sleep(3)
            
            # ì§„í–‰ìƒí™© ì €ì¥
            self.save_progress(category, i + batch_size)
    
    def save_progress(self, category: str, completed_count: int):
        """ì§„í–‰ìƒí™©ì„ JSON íŒŒì¼ë¡œ ì €ì¥"""
        progress_data = {
            "timestamp": datetime.now().isoformat(),
            "session_start": self.session_start.isoformat(),
            "category": category,
            "completed_count": completed_count,
            "crawled_data": self.crawled_data,
            "failed_pals": self.failed_pals,
            "total_crawled": len(self.crawled_data)
        }
        
        filename = f"missing_pals_progress_{category}_{completed_count}.json"
        with open(filename, 'w', encoding='utf-8') as f:
            json.dump(progress_data, f, ensure_ascii=False, indent=2)
        
        print(f"ğŸ’¾ ì§„í–‰ìƒí™© ì €ì¥ë¨: {filename}")
    
    def run_full_crawl(self):
        """ì „ì²´ ëˆ„ë½ íŒ° í¬ë¡¤ë§ ì‹¤í–‰"""
        print("=" * 60)
        print("ğŸ¯ íŒ°ì›”ë“œ ëˆ„ë½ íŒ° ë°°ì¹˜ í¬ë¡¤ë§ ì‹œì‘")
        print(f"ğŸ“… ì‹œì‘ ì‹œê°„: {self.session_start.strftime('%Y-%m-%d %H:%M:%S')}")
        print("=" * 60)
        
        total_missing = sum(len(pal_list) for pal_list in self.missing_pals.values())
        print(f"ğŸ“Š ì´ ëˆ„ë½ íŒ°: {total_missing}ê°œ")
        
        for category, pal_list in self.missing_pals.items():
            print(f"   - {category}: {len(pal_list)}ê°œ")
        
        # ì¹´í…Œê³ ë¦¬ë³„ ìˆœì°¨ í¬ë¡¤ë§
        for category, pal_list in self.missing_pals.items():
            self.batch_crawl_category(category, pal_list)
        
        # ìµœì¢… ê²°ê³¼ ì €ì¥
        self.save_final_results()
        self.generate_csv_output()
        
        print("\n" + "=" * 60)
        print("ğŸ‰ í¬ë¡¤ë§ ì™„ë£Œ!")
        print(f"âœ… ì„±ê³µ: {len(self.crawled_data)}ê°œ")
        print(f"âŒ ì‹¤íŒ¨: {len(self.failed_pals)}ê°œ")
        if self.failed_pals:
            print(f"ì‹¤íŒ¨ ëª©ë¡: {', '.join(self.failed_pals)}")
        print("=" * 60)
    
    def save_final_results(self):
        """ìµœì¢… ê²°ê³¼ë¥¼ JSONìœ¼ë¡œ ì €ì¥"""
        final_results = {
            "crawl_session": {
                "start_time": self.session_start.isoformat(),
                "end_time": datetime.now().isoformat(),
                "total_attempted": sum(len(pal_list) for pal_list in self.missing_pals.values()),
                "total_success": len(self.crawled_data),
                "total_failed": len(self.failed_pals)
            },
            "crawled_data": self.crawled_data,
            "failed_pals": self.failed_pals
        }
        
        filename = f"missing_pals_final_results_{datetime.now().strftime('%Y%m%d_%H%M%S')}.json"
        with open(filename, 'w', encoding='utf-8') as f:
            json.dump(final_results, f, ensure_ascii=False, indent=2)
        
        print(f"ğŸ’¾ ìµœì¢… ê²°ê³¼ ì €ì¥ë¨: {filename}")
    
    def generate_csv_output(self):
        """í¬ë¡¤ë§ ê²°ê³¼ë¥¼ CSVë¡œ ë³€í™˜"""
        if not self.crawled_data:
            print("âš ï¸ í¬ë¡¤ë§ëœ ë°ì´í„°ê°€ ì—†ì–´ CSV ìƒì„±ì„ ê±´ë„ˆëœë‹ˆë‹¤.")
            return
        
        filename = f"missing_pals_crawled_{datetime.now().strftime('%Y%m%d_%H%M%S')}.csv"
        
        # CSV í•„ë“œëª… (ê¸°ì¡´ ë°ì´í„°ì™€ í˜¸í™˜)
        fieldnames = [
            "id", "name", "englishName", "description", "type1", "type2",
            "hp", "attack", "defense", "rarity", "size", "foodAmount",
            "partnerSkill", "work1", "work2", "work3", "activeSkills",
            "dropItem1", "dropItem2", "eggType", "imageFile"
        ]
        
        with open(filename, 'w', newline='', encoding='utf-8') as csvfile:
            writer = csv.DictWriter(csvfile, fieldnames=fieldnames)
            writer.writeheader()
            
            for pal_data in self.crawled_data.values():
                writer.writerow(pal_data)
        
        print(f"ğŸ“„ CSV íŒŒì¼ ìƒì„±ë¨: {filename}")

def main():
    """ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜"""
    crawler = PalBatchCrawler()
    crawler.run_full_crawl()

if __name__ == "__main__":
    main() 