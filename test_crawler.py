#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
íŒ°ì›”ë“œ í¬ë¡¤ëŸ¬ í…ŒìŠ¤íŠ¸ ìŠ¤í¬ë¦½íŠ¸
ìš°ì„ ìˆœìœ„ í•­ëª©ë“¤ì´ ì œëŒ€ë¡œ ì‘ë™í•˜ëŠ”ì§€ í™•ì¸
"""

import requests
import csv
import json
import time
import re
from typing import Dict, List
from bs4 import BeautifulSoup

class TestPalCrawler:
    def __init__(self):
        self.base_url = "https://paldb.cc"
        self.session = requests.Session()
        self.session.headers.update({
            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36'
        })
        
    def get_pal_detail_url(self, pal_id: str) -> str:
        """íŒ° IDë¡œë¶€í„° ìƒì„¸ í˜ì´ì§€ URLì„ ìƒì„±í•©ë‹ˆë‹¤"""
        if 'B' in pal_id:
            base_id = pal_id.replace('B', '')
            return f"{self.base_url}/ko/Pal/{base_id}/Variant"
        else:
            return f"{self.base_url}/ko/Pal/{pal_id}"
    
    def test_passive_skills_extraction(self, soup: BeautifulSoup, pal_id: str) -> Dict:
        """Passive Skills ì¶”ì¶œ í…ŒìŠ¤íŠ¸"""
        print(f"  ğŸ” Passive Skills ì¶”ì¶œ í…ŒìŠ¤íŠ¸ - {pal_id}")
        passive_data = {}
        
        try:
            passive_skills = []
            
            # ì „ì²´ í…ìŠ¤íŠ¸ì—ì„œ íŒ¨ì‹œë¸Œ ê´€ë ¨ ë‚´ìš© ì°¾ê¸°
            all_text = soup.get_text()
            print(f"    ì „ì²´ í…ìŠ¤íŠ¸ ê¸¸ì´: {len(all_text)}ì")
            
            # LV íŒ¨í„´ì´ ìˆëŠ” ìŠ¤í‚¬ ì°¾ê¸°
            lv_patterns = re.findall(r'([ê°€-í£\s]{3,20})\s*LV\s*\d+', all_text)
            print(f"    LV íŒ¨í„´ ë§¤ì¹­: {len(lv_patterns)}ê°œ")
            for pattern in lv_patterns[:5]:  # ì²˜ìŒ 5ê°œë§Œ ì¶œë ¥
                print(f"      - {pattern}")
            
            # ì¼ë°˜ì ì¸ ìŠ¤í‚¬ í‚¤ì›Œë“œ ì°¾ê¸°
            skill_keywords = ['ê³µê²©ë ¥', 'ë°©ì–´ë ¥', 'ì²´ë ¥', 'ì´ë™ì†ë„', 'ì‘ì—…ì†ë„', 'í¬íšë¥ ']
            for keyword in skill_keywords:
                if keyword in all_text:
                    print(f"    í‚¤ì›Œë“œ '{keyword}' ë°œê²¬")
                    # ì£¼ë³€ í…ìŠ¤íŠ¸ ì¶”ì¶œ
                    context_matches = re.finditer(f'.{{0,50}}{keyword}.{{0,50}}', all_text)
                    for match in list(context_matches)[:2]:  # ì²˜ìŒ 2ê°œë§Œ
                        context = match.group().strip()
                        print(f"      ì»¨í…ìŠ¤íŠ¸: {context}")
            
            # ì‹¤ì œ íŒ¨ì‹œë¸Œ ìŠ¤í‚¬ ë¦¬ìŠ¤íŠ¸ êµ¬ì„±
            for pattern in lv_patterns:
                skill_name = pattern.strip()
                if skill_name and len(skill_name) > 2 and skill_name not in passive_skills:
                    passive_skills.append(skill_name)
            
            passive_data['passiveSkills'] = " | ".join(passive_skills) if passive_skills else ""
            passive_data['passiveSkills_count'] = len(passive_skills)
            
            print(f"    âœ… ìµœì¢… Passive Skills: {len(passive_skills)}ê°œ")
            if passive_skills:
                for skill in passive_skills[:3]:  # ì²˜ìŒ 3ê°œë§Œ ì¶œë ¥
                    print(f"      - {skill}")
                    
        except Exception as e:
            print(f"    âŒ Passive Skills ì¶”ì¶œ ì˜¤ë¥˜: {e}")
            passive_data = {'passiveSkills': '', 'passiveSkills_count': 0}
            
        return passive_data
    
    def test_active_skills_extraction(self, soup: BeautifulSoup, pal_id: str) -> Dict:
        """Active Skills ìƒì„¸ ì •ë³´ ì¶”ì¶œ í…ŒìŠ¤íŠ¸"""
        print(f"  ğŸ” Active Skills ì¶”ì¶œ í…ŒìŠ¤íŠ¸ - {pal_id}")
        skills_data = {}
        
        try:
            # ê¸°ì¡´ activeSkills í˜•íƒœì˜ í…ìŠ¤íŠ¸ ì°¾ê¸°
            all_text = soup.get_text()
            
            # ìŠ¤í‚¬ íŒ¨í„´ ë§¤ì¹­: "ìŠ¤í‚¬ëª…(ì†ì„±, íŒŒì›Œ, ì¿¨íƒ€ì„)"
            skill_patterns = re.findall(r'([^|\(]+)\(([^,]+),\s*(\d+)\s*íŒŒì›Œ,\s*(\d+)\s*ì´ˆ\)', all_text)
            print(f"    ìŠ¤í‚¬ íŒ¨í„´ ë§¤ì¹­: {len(skill_patterns)}ê°œ")
            
            active_skills = []
            for pattern in skill_patterns:
                skill_info = {
                    'name': pattern[0].strip(),
                    'element': pattern[1].strip(),
                    'power': pattern[2],
                    'cooltime': pattern[3]
                }
                active_skills.append(skill_info)
                print(f"      - {skill_info['name']}: {skill_info['element']}, {skill_info['power']}íŒŒì›Œ, {skill_info['cooltime']}ì´ˆ")
            
            # í…Œì´ë¸”ì—ì„œ ìŠ¤í‚¬ ì •ë³´ ì°¾ê¸°
            tables = soup.find_all('table')
            print(f"    í…Œì´ë¸” ê°œìˆ˜: {len(tables)}ê°œ")
            
            for i, table in enumerate(tables):
                print(f"      í…Œì´ë¸” {i+1}: {len(table.find_all('tr'))}í–‰")
                rows = table.find_all('tr')
                if len(rows) > 1:  # í—¤ë” + ë°ì´í„° í–‰ì´ ìˆëŠ” ê²½ìš°
                    for j, row in enumerate(rows[:3]):  # ì²˜ìŒ 3í–‰ë§Œ í™•ì¸
                        cells = row.find_all(['td', 'th'])
                        if cells:
                            row_text = " | ".join([cell.get_text().strip() for cell in cells])
                            print(f"        í–‰ {j+1}: {row_text[:100]}...")
            
            skills_data['activeSkills_detailed'] = json.dumps(active_skills, ensure_ascii=False) if active_skills else ""
            skills_data['activeSkills_count'] = len(active_skills)
            
            print(f"    âœ… ìµœì¢… Active Skills: {len(active_skills)}ê°œ")
            
        except Exception as e:
            print(f"    âŒ Active Skills ì¶”ì¶œ ì˜¤ë¥˜: {e}")
            skills_data = {'activeSkills_detailed': '', 'activeSkills_count': 0}
            
        return skills_data
    
    def test_crawl_pal(self, pal_id: str) -> Dict:
        """ë‹¨ì¼ íŒ° í¬ë¡¤ë§ í…ŒìŠ¤íŠ¸"""
        url = self.get_pal_detail_url(pal_id)
        print(f"\nğŸ” í…ŒìŠ¤íŠ¸ í¬ë¡¤ë§: {pal_id}")
        print(f"  URL: {url}")
        
        try:
            response = self.session.get(url, timeout=10)
            response.raise_for_status()
            print(f"  âœ… HTTP ì‘ë‹µ: {response.status_code}")
            
            soup = BeautifulSoup(response.content, 'html.parser')
            print(f"  âœ… HTML íŒŒì‹± ì™„ë£Œ: {len(soup.get_text())}ì")
            
            pal_data = {'id': pal_id, 'url': url}
            
            # Passive Skills í…ŒìŠ¤íŠ¸
            pal_data.update(self.test_passive_skills_extraction(soup, pal_id))
            
            # Active Skills í…ŒìŠ¤íŠ¸  
            pal_data.update(self.test_active_skills_extraction(soup, pal_id))
            
            return pal_data
            
        except Exception as e:
            print(f"  âŒ í¬ë¡¤ë§ ì˜¤ë¥˜: {e}")
            return {'id': pal_id, 'error': str(e)}
    
    def run_test(self):
        """í…ŒìŠ¤íŠ¸ ì‹¤í–‰"""
        print("ğŸ§ª íŒ°ì›”ë“œ í¬ë¡¤ëŸ¬ í…ŒìŠ¤íŠ¸ ì‹œì‘")
        print("=" * 60)
        
        # í…ŒìŠ¤íŠ¸í•  íŒ°ë“¤ (ì¼ë°˜ + B variant)
        test_pals = ['1', '2', '5B', '10B']
        
        results = []
        
        for pal_id in test_pals:
            result = self.test_crawl_pal(pal_id)
            results.append(result)
            time.sleep(3)  # ì„œë²„ ë¶€í•˜ ë°©ì§€
        
        # ê²°ê³¼ ìš”ì•½
        print("\n" + "=" * 60)
        print("ğŸ“Š í…ŒìŠ¤íŠ¸ ê²°ê³¼ ìš”ì•½")
        print("=" * 60)
        
        for result in results:
            pal_id = result['id']
            if 'error' in result:
                print(f"âŒ {pal_id}: ì˜¤ë¥˜ - {result['error']}")
            else:
                passive_count = result.get('passiveSkills_count', 0)
                active_count = result.get('activeSkills_count', 0)
                passive_text = result.get('passiveSkills', '')
                active_text = result.get('activeSkills_detailed', '')
                
                print(f"âœ… {pal_id}:")
                print(f"  Passive Skills: {passive_count}ê°œ")
                if passive_text:
                    print(f"    {passive_text[:100]}...")
                print(f"  Active Skills: {active_count}ê°œ")
                if active_text:
                    print(f"    {active_text[:100]}...")
        
        # ì„±ê³µë¥  ê³„ì‚°
        successful = sum(1 for r in results if 'error' not in r)
        success_rate = (successful / len(results)) * 100
        
        print(f"\nğŸ“ˆ ì„±ê³µë¥ : {successful}/{len(results)} ({success_rate:.1f}%)")
        
        if success_rate >= 75:
            print("âœ… í…ŒìŠ¤íŠ¸ í†µê³¼! ë³¸ê²©ì ì¸ í¬ë¡¤ë§ì„ ì§„í–‰í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.")
        else:
            print("âš ï¸ í…ŒìŠ¤íŠ¸ ê²°ê³¼ê°€ ì¢‹ì§€ ì•ŠìŠµë‹ˆë‹¤. í¬ë¡¤ë§ ë¡œì§ì„ ê°œì„ í•´ì•¼ í•©ë‹ˆë‹¤.")
        
        return results

def main():
    """ë©”ì¸ í•¨ìˆ˜"""
    crawler = TestPalCrawler()
    results = crawler.run_test()
    
    # ê²°ê³¼ë¥¼ JSONìœ¼ë¡œ ì €ì¥
    with open('crawler_test_results.json', 'w', encoding='utf-8') as f:
        json.dump(results, f, ensure_ascii=False, indent=2)
    
    print(f"\nğŸ’¾ í…ŒìŠ¤íŠ¸ ê²°ê³¼ ì €ì¥: crawler_test_results.json")

if __name__ == "__main__":
    main() 