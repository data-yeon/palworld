#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
μμ •λ ν°μ›”λ“ ν¬λ΅¤λ¬ - μ¬λ°”λ¥Έ URL κµ¬μ΅° μ‚¬μ©
μ°μ„ μμ„: passiveSkills + Active Skills μƒμ„Έ + B variants
"""

import requests
import csv
import json
import time
import re
from typing import Dict, List
from bs4 import BeautifulSoup

class FixedPalCrawler:
    def __init__(self):
        self.base_url = "https://paldb.cc"
        self.session = requests.Session()
        self.session.headers.update({
            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36'
        })
        
        # μ‹¤μ  μ‚¬μ΄νΈμ—μ„ ν™•μΈλ ν° μ΄λ¦„ λ§¤ν•‘ (ID -> URL μ΄λ¦„)
        self.pal_url_mapping = {
            "1": "Lamball",
            "2": "Cattiva", 
            "3": "Chikipi",
            "4": "Lifmunk",
            "5": "Foxparks",
            "5B": "Foxparks_Cryst",
            "6": "Fuack",
            "6B": "Fuack_Ignis",
            "7": "Sparkit",
            "8": "Tanzee",
            "9": "Rooby",
            "10": "Pengullet",
            "10B": "Pengullet_Lux",
            "11": "Penking",
            "11B": "Penking_Lux",
            "12": "Jolthog",
            "12B": "Jolthog_Cryst"
        }
        
    def get_pal_url(self, pal_id: str) -> str:
        """ν° IDλ΅λ¶€ν„° μ‹¤μ  URLμ„ μƒμ„±ν•©λ‹λ‹¤"""
        if pal_id in self.pal_url_mapping:
            pal_name = self.pal_url_mapping[pal_id]
            return f"{self.base_url}/ko/{pal_name}"
        else:
            # λ§¤ν•‘μ— μ—†λ” κ²½μ° κΈ°λ³Έ ν¨ν„΄ μ‹λ„
            return f"{self.base_url}/ko/Pal{pal_id}"
    
    def extract_passive_skills_smart(self, soup: BeautifulSoup, pal_id: str) -> Dict:
        """μ¤λ§νΈν• Passive Skills μ¶”μ¶"""
        print(f"  π” Passive Skills μ¶”μ¶ - {pal_id}")
        passive_data = {}
        
        try:
            passive_skills = []
            all_text = soup.get_text()
            
            # ν¨ν„΄ 1: LV μ«μμ™€ ν•¨κ» λ‚μ¤λ” μ¤ν‚¬λ…
            lv_patterns = re.findall(r'([κ°€-ν£\s]{3,20})\s*LV\s*\d+', all_text)
            print(f"    LV ν¨ν„΄: {len(lv_patterns)}κ°")
            
            # ν¨ν„΄ 2: "μ¤ν‚¬" ν‚¤μ›λ“ μ£Όλ³€ ν…μ¤νΈ
            skill_sections = re.findall(r'.{0,100}μ¤ν‚¬.{0,100}', all_text)
            print(f"    μ¤ν‚¬ μ„Ήμ…: {len(skill_sections)}κ°")
            
            # ν¨ν„΄ 3: μΌλ°μ μΈ ν¨μ‹λΈ μ¤ν‚¬ ν¨κ³Ό λ‹¨μ–΄λ“¤
            passive_keywords = ['μ¦κ°€', 'κ°μ†', 'κ°•ν™”', 'ν¨μ¨', 'μ €ν•­', 'λ©΄μ—­', 'λ°λ―Έμ§€', 'κ³µκ²©λ ¥', 'λ°©μ–΄λ ¥', 'μ²΄λ ¥']
            for keyword in passive_keywords:
                if keyword in all_text:
                    # ν‚¤μ›λ“ μ£Όλ³€μ—μ„ LV ν¨ν„΄ μ°ΎκΈ°
                    context_patterns = re.findall(
                        f'([κ°€-ν£\s]{{3,15}}){keyword}[^κ°€-ν£]*LV\s*\d+',
                        all_text
                    )
                    if context_patterns:
                        print(f"    '{keyword}' κ΄€λ ¨ μ¤ν‚¬: {len(context_patterns)}κ°")
                        passive_skills.extend(context_patterns)
            
            # μ¤‘λ³µ μ κ±° λ° μ •λ¦¬
            clean_skills = []
            for skill in lv_patterns + passive_skills:
                skill_clean = skill.strip()
                if (skill_clean and 
                    len(skill_clean) > 2 and 
                    skill_clean not in clean_skills and
                    not any(char.isdigit() for char in skill_clean)):  # μ«μ ν¬ν•¨λ κ²ƒ μ μ™Έ
                    clean_skills.append(skill_clean)
            
            passive_data['passiveSkills'] = " | ".join(clean_skills[:5]) if clean_skills else ""  # μµλ€ 5κ°κΉμ§€
            passive_data['passiveSkills_count'] = len(clean_skills)
            
            print(f"    β… μµμΆ… Passive Skills: {len(clean_skills)}κ°")
            if clean_skills:
                for skill in clean_skills[:3]:
                    print(f"      - {skill}")
                    
        except Exception as e:
            print(f"    β Passive Skills μ¶”μ¶ μ¤λ¥: {e}")
            passive_data = {'passiveSkills': '', 'passiveSkills_count': 0}
            
        return passive_data
    
    def extract_active_skills_smart(self, soup: BeautifulSoup, pal_id: str) -> Dict:
        """μ¤λ§νΈν• Active Skills μƒμ„Έ μ •λ³΄ μ¶”μ¶"""
        print(f"  π” Active Skills μ¶”μ¶ - {pal_id}")
        skills_data = {}
        
        try:
            all_text = soup.get_text()
            active_skills = []
            
            # ν¨ν„΄ 1: κΈ°μ΅΄ ν•μ‹ "μ¤ν‚¬λ…(μ†μ„±, νμ›, μΏ¨νƒ€μ„)"
            pattern1 = re.findall(r'([^(]+)\(([^,]+),\s*(\d+)\s*νμ›,\s*(\d+)\s*μ΄\)', all_text)
            for match in pattern1:
                skill_info = {
                    'name': match[0].strip(),
                    'element': match[1].strip(),
                    'power': match[2],
                    'cooltime': match[3]
                }
                active_skills.append(skill_info)
            
            # ν¨ν„΄ 2: μ†μ„±κ³Ό νμ›, μΏ¨νƒ€μ„μ΄ λ¶„λ¦¬λ ν•νƒ
            skill_blocks = re.findall(r'([κ°€-ν£\s]{2,20})\s*(?:μ†μ„±|element)[^0-9]*(\d+)[^0-9]*νμ›[^0-9]*(\d+)[^0-9]*μ΄', all_text, re.IGNORECASE)
            for match in skill_blocks:
                skill_info = {
                    'name': match[0].strip(),
                    'element': 'λ―Έν™•μΈ',
                    'power': match[1],
                    'cooltime': match[2]
                }
                active_skills.append(skill_info)
            
            # ν¨ν„΄ 3: ν…μ΄λΈ”μ—μ„ μ¤ν‚¬ μ •λ³΄ μ¶”μ¶
            tables = soup.find_all('table')
            for table in tables:
                rows = table.find_all('tr')
                for row in rows:
                    cells = row.find_all(['td', 'th'])
                    if len(cells) >= 3:
                        cell_texts = [cell.get_text().strip() for cell in cells]
                        
                        # μ¤ν‚¬λ…, μ†μ„±, νμ›, μΏ¨νƒ€μ„ ν¨ν„΄ μ°ΎκΈ°
                        skill_name = ""
                        element = ""
                        power = ""
                        cooltime = ""
                        
                        for i, text in enumerate(cell_texts):
                            if re.match(r'^[κ°€-ν£\s]{2,20}$', text) and not skill_name:
                                skill_name = text
                            elif any(elem in text for elem in ['ν™”μ—Ό', 'λ¬Ό', 'ν’€', 'μ–Όμ', 'λ²κ°', 'λ•…', 'μ–΄λ‘ ', 'λ¬΄μ†μ„±']):
                                element = text
                            elif re.search(r'(\d+).*νμ›', text):
                                power = re.search(r'(\d+)', text).group(1)
                            elif re.search(r'(\d+).*μ΄', text):
                                cooltime = re.search(r'(\d+)', text).group(1)
                        
                        if skill_name and (power or cooltime):
                            skill_info = {
                                'name': skill_name,
                                'element': element or 'λ―Έν™•μΈ',
                                'power': power or '0',
                                'cooltime': cooltime or '0'
                            }
                            active_skills.append(skill_info)
            
            # μ¤‘λ³µ μ κ±°
            unique_skills = []
            seen_names = set()
            for skill in active_skills:
                if skill.get('name') and skill['name'] not in seen_names:
                    unique_skills.append(skill)
                    seen_names.add(skill['name'])
            
            skills_data['activeSkills_detailed'] = json.dumps(unique_skills, ensure_ascii=False) if unique_skills else ""
            skills_data['activeSkills_count'] = len(unique_skills)
            
            print(f"    β… Active Skills: {len(unique_skills)}κ°")
            for skill in unique_skills[:2]:  # μ²μ 2κ°λ§ μ¶λ ¥
                print(f"      - {skill['name']}: {skill['element']}, {skill['power']}νμ›, {skill['cooltime']}μ΄")
                
        except Exception as e:
            print(f"    β Active Skills μ¶”μ¶ μ¤λ¥: {e}")
            skills_data = {'activeSkills_detailed': '', 'activeSkills_count': 0}
            
        return skills_data
    
    def crawl_pal_data(self, pal_id: str) -> Dict:
        """λ‹¨μΌ ν° λ°μ΄ν„° ν¬λ΅¤λ§"""
        url = self.get_pal_url(pal_id)
        print(f"π” ν¬λ΅¤λ§: {pal_id} - {url}")
        
        try:
            response = self.session.get(url, timeout=15)
            response.raise_for_status()
            print(f"  β… HTTP μ‘λ‹µ: {response.status_code}")
            
            soup = BeautifulSoup(response.content, 'html.parser')
            
            pal_data = {'id': pal_id, 'url': url}
            
            # μ°μ„ μμ„ 1: Passive Skills
            pal_data.update(self.extract_passive_skills_smart(soup, pal_id))
            
            # μ°μ„ μμ„ 2: Active Skills μƒμ„Έ μ •λ³΄
            pal_data.update(self.extract_active_skills_smart(soup, pal_id))
            
            # κΈ°λ³Έ μ •λ³΄ μ¶”μ¶
            title = soup.find('title')
            if title:
                pal_data['name_extracted'] = title.get_text().strip()
            
            return pal_data
            
        except requests.exceptions.RequestException as e:
            print(f"  β λ„¤νΈμ›ν¬ μ¤λ¥: {e}")
            return {'id': pal_id, 'error': f'network_error: {str(e)}'}
        except Exception as e:
            print(f"  β νμ‹± μ¤λ¥: {e}")
            return {'id': pal_id, 'error': f'parsing_error: {str(e)}'}
    
    def test_priority_crawling(self):
        """μ°μ„ μμ„ ν¬λ΅¤λ§ ν…μ¤νΈ"""
        print("π§ μ°μ„ μμ„ ν¬λ΅¤λ§ ν…μ¤νΈ μ‹μ‘")
        print("=" * 60)
        
        # ν…μ¤νΈν•  ν°λ“¤ (URL λ§¤ν•‘ ν™•μΈλ κ²ƒλ“¤)
        test_pals = ['1', '2', '5B', '10B']
        
        results = []
        success_count = 0
        
        for pal_id in test_pals:
            result = self.crawl_pal_data(pal_id)
            results.append(result)
            
            if 'error' not in result:
                success_count += 1
            
            time.sleep(3)  # μ„λ²„ λ¶€ν• λ°©μ§€
        
        # κ²°κ³Ό μ”μ•½
        print("\n" + "=" * 60)
        print("π“ ν…μ¤νΈ κ²°κ³Ό μ”μ•½")
        print("=" * 60)
        
        for result in results:
            pal_id = result['id']
            if 'error' in result:
                print(f"β {pal_id}: {result['error']}")
            else:
                passive_count = result.get('passiveSkills_count', 0)
                active_count = result.get('activeSkills_count', 0)
                
                print(f"β… {pal_id}:")
                print(f"  Passive Skills: {passive_count}κ°")
                print(f"  Active Skills: {active_count}κ°")
                
                if result.get('passiveSkills'):
                    print(f"    ν¨μ‹λΈ: {result['passiveSkills'][:100]}...")
                if result.get('activeSkills_detailed'):
                    print(f"    μ•΅ν‹°λΈ: {result['activeSkills_detailed'][:100]}...")
        
        success_rate = (success_count / len(test_pals)) * 100
        print(f"\nπ“ μ„±κ³µλ¥ : {success_count}/{len(test_pals)} ({success_rate:.1f}%)")
        
        # κ²°κ³Όλ¥Ό JSONμΌλ΅ μ €μ¥
        with open('fixed_crawler_test_results.json', 'w', encoding='utf-8') as f:
            json.dump(results, f, ensure_ascii=False, indent=2)
        
        print(f"π’Ύ ν…μ¤νΈ κ²°κ³Ό μ €μ¥: fixed_crawler_test_results.json")
        
        if success_rate >= 75:
            print("β… ν…μ¤νΈ ν†µκ³Ό! λ³Έκ²©μ μΈ ν¬λ΅¤λ§ μ§„ν–‰ κ°€λ¥")
            return True
        else:
            print("β οΈ ν…μ¤νΈ μ‹¤ν¨. URL λ§¤ν•‘μ΄λ‚ νμ‹± λ΅μ§ κ°μ„  ν•„μ”")
            return False

def main():
    """λ©”μΈ ν•¨μ"""
    print("π― μμ •λ ν°μ›”λ“ ν¬λ΅¤λ¬")
    print("μ¬λ°”λ¥Έ URL κµ¬μ΅° μ‚¬μ©")
    
    crawler = FixedPalCrawler()
    
    # μ°μ„ μμ„ ν¬λ΅¤λ§ ν…μ¤νΈ
    success = crawler.test_priority_crawling()
    
    if success:
        print("\nπ€ ν…μ¤νΈ μ„±κ³µ! μ΄μ  μ „μ²΄ ν¬λ΅¤λ§μ„ μ‹¤ν–‰ν•  μ μμµλ‹λ‹¤.")
    else:
        print("\nπ”§ ν…μ¤νΈ μ‹¤ν¨. λ¬Έμ λ¥Ό μμ •ν• ν›„ λ‹¤μ‹ μ‹λ„ν•μ„Έμ”.")

if __name__ == "__main__":
    main() 